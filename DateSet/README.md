# 实验数据集处理过程
---
## 主要思路：
###  1.数据集标签
###  2.将流量数据转化为会话以及过滤
###  3.将会话数据转为十六进制字节码并归一化
###  4.选取定长向量


## 一、数据集标签
---
- 数据来源：IDS-2017
- 因为原始数据集是Pcap形式的原始流量，因此我们需要自行对其每一分类做出标签。
	### 主要思路：
	---
	1. 以数据集主页提供信息以及CIC实验室所给出的它们标签好的CSV格式数据集的信息为参考，确定时间区间与IP列表来选取流量;
	2. 因为所提供的Pcap原始文件体积都偏大，Python脚本无法直接处理。因此先利用Wireshark所提供的命令行工具Editcap，筛选出某时间段内的通信流量。例如，参考信息中所提供的标签A的流量通信时间为StartTime-OverTime，则先筛选出这个时间段类流量；
	3. 通过第一步筛选，可能数据包仍然很大，Python脚本依旧无法直接处理，继续使用Editcap工具将大Pcap包切分成若干个小的Pcap包处理；
	4. 编写Python脚本 GenerateLabel.py ，根据上述提到的参考信息，通过设置时间和IP地址的方法，筛选出所需流量。
	5. 主要时差和夏令时的问题，数据集使用的为 -4区 时间。
	6. 注意：Editcap可能会破坏Pcap文件的解析结构，后续会话操作工具可能无法处理，必要时，可以通过scapy库重写一下pcap文件。
	### 筛选时间信息和IP列表
	---
	- 注：并不一定是源IP就是攻击者IP，标记信息主要CIC实验室给出的标记流量通信双方IP地址。
	#### Benign
	- 数据集中正常流量是从8：55采集到10:34。
	- 我们选取Monday从9：00 -- 9：10   9：30--9：40  10：00-10：10三个时段的流量
	
	#### Botnet
	- IP列表: ['205.174.165.73','192.168.10.9','192.168.10.8','192.168.10.5','192.168.10.15','192.168.10.14']
	- 时间段: 2017-07-07 10:00:00 -- 2017-07-07 13:00:00
	
	#### PortScan
	- IP列表: 源：['172.16.0.1']  目的['192.168.10.50']             
	- 时间段: 2017-07-07 13:00:00 -- 2017-07-07 15:30:00
	
	#### DDos
	- 从Csv格式的该项数据发现，16：10之后相同IP下含有许多标签为Benign数据，因此抛弃之后数据。
	- IP列表: 源：['172.16.0.1']  目的['192.168.10.50']             
	- 时间段: 2017-07-07 15:55:00 -- 2017-07-07 16:10:00
	
	#### Web Attack - Brute Force
	- IP列表: 源：['172.16.0.1']  目的['192.168.10.50']            
	- 时间段: 2017-07-06 09:20:00 -- 2017-07-06 10:00:00

	#### Web Attack - XSS
	- IP列表: 源：['172.16.0.1']  目的['192.168.10.50']             
	- 时间段: 2017-07-06 10:15:00 -- 2017-07-06 10:35:00

	#### Web Attack - Sql Injection
	- IP列表: 源：['172.16.0.1']  目的['192.168.10.50']            
	- 时间段: 2017-07-06 10:40:00 -- 2017-07-06 10:42:00

	#### FTP - Patator
	- IP列表:  源：['172.16.0.1']  目的['192.168.10.50'] 
	- 时间段: 2017-07-04 09:20:00 -- 2017-07-04 10:20:00

	#### SSH - Patator
	- IP列表:  源：['172.16.0.1']  目的['192.168.10.50'] 
	- 时间段: 2017-07-04 14:10:00 -- 2017-07-04 15:00:00

	#### Dos Slowloris
	- IP列表:  源 ['172.16.0.1']    目的   ['192.168.10.50']
	- 时间段: 2017-07-05 09:47:00 -- 2017-07-05 10:10:00

	#### Dos Slowhttptest
	- IP列表:  源 ['172.16.0.1']    目的   ['192.168.10.50']
	- 时间段: 2017-07-05 10:15:00 -- 2017-07-05 10:35:00

	#### Dos Hulk
	- IP列表:  源 ['172.16.0.1']    目的   ['192.168.10.50']
	- 时间段: 2017-07-05 10:43:00 -- 2017-07-05 11:00:00

	#### Dos GoldenEye
	- IP列表:  源 ['172.16.0.1']    目的   ['192.168.10.50']
	- 时间段: 2017-07-05 11:10:00 -- 2017-07-05 11:20:00

	#### Heartbleed Port 444
	- IP列表:  源 ['172.16.0.1']    目的   ['192.168.10.51']
	- 时间段: 2017-07-05 15:12:00 -- 2017-07-05 15:32:00

	#### Infiltration
	- IP列表：源 ['192.168.10.8']      目的 ['205.174.165.73']
	- 时间段：2017-07-06 14:19:00 -- 2017-07-06 14:42:00   2017-07-06 15:05:00--2017-07-06 15:45:00
	- 这个类型的标签工作存疑。CIC网页描述，有两个受害者IP,但在其csv标记下只有一个受害者IP。且在Csv描述中另外一个IP与攻击者IP直接通信流量很少，且被标记为良性。

## 二、流量数据转化为会话
---
- 我们主要使用USTC-TK2016工具集中的会话切分工具，来将我们的流量数据转化为会话，而它的工具实际是在SplitCap工具上再开发的。
- 根据SplitCap工具的描述(https://www.netresec.com/index.ashx?page=SplitCap)，以及USTC-TK2016的脚本代码，其实现会话的方式可能是通过五元组（源IP，源端口，目的IP，目的端口，协议），来将一个大的Pcap文件
划分成单独的TCP或者UDP会话。
- 根据我们使用后的划分结果来看，工具可能没有考虑一个时间阈值问题；
- 我们根据第一步选取的源IP和目的IP，将会话进行过滤。过滤掉从目的IP发往源IP处的会话；
- 过滤的同时，我们根据会话的体积再做出一些筛选，尽可能的使每一分类下的体积尽量均一。
	### 统计信息
	---
	#### Benign
	- 过滤前：23884
	- 过滤后：23884
	
	#### Botnet
	- 过滤前：1226
	- 过滤后：1226
	
	#### PortScan
	- 过滤前：159939
	- 过滤后：159109
	
	#### DDos
	- 过滤前：35357
	- 过滤后：34896
	
	#### Web Attack - Brute Force
	- 过滤前：1349
	- 过滤后：70
	- 根据攻击特点，保留了实际有http通信的

	#### Web Attack - XSS
	- 过滤前：661
	- 过滤后：18
	- 根据攻击特点，保留了实际有http通信的

	#### Web Attack - Sql Injection
	- 过滤前：9
	- 过滤后：9

	#### FTP - Patator
	- 过滤前：3958
	- 过滤后：3912

	#### SSH - Patator
	- 过滤前：2424
	- 过滤后：2404

	#### Dos Slowloris
	- 过滤前：3860
	- 过滤后：1784
	
	#### Dos Slowhttptest
	- 过滤前：4212
	- 过滤后：1103

	#### Dos Hulk
	- 过滤前：14108
	- 过滤后：13904

	#### Dos GoldenEye
	- 过滤前：7574
	- 过滤后：7472

	#### Heartbleed Port 444
	- 无法切分会话

	#### Infiltration
	- 过滤前：6
	- 过滤后：6
	
	
## 三、将会话转化为十六进制字节码并归一化
---
- 
	### Header数据的过滤
	---
	- 因为一个Pcap类型文件中会包含一个PcapHeader和若干个PacketHeader。在我们的工作中，这些数据属于噪音数据，因此需要过滤。
	- PcapHeader占Pcap文件的前24个字节
	- 每个PacketHeader占16个字节，其中最后4个字节组成的数字表示该Packet包的大小。例如，在16进制下，最后四个字节为0000 0000 0000 0201，表示该包大小为512个字节。
	- 通过以上这些信息即可实现对于 Header 数据的过滤
	### 关于数据的标准化
	---
	- 实验过程：
		1. 将数据按每个字节用十六进制表示
		2. 将两位十六进制转化为0-255整数
		3. 将整数归一化为0-1
	- 但在实际过程中，选择直接将字节数据转化为0-1之间的整数。
	### 其他说明
	---
	- 对面样本数目超过10000的类别，暂时随机选择10000个样本处理
	
## 四、选取定长向量
---
- 将上一步归一化后的数据定长选取即可；
- 假设定长为n=500，那么超过500字节的进行截断处理，不足500字节的补零处理。相应地，分开存储在Truncate和Padding中；
- 文件存储格式为Csv
	
	